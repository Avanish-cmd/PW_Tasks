{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "179906e9-9ace-45f5-abc2-7a190e3f98db",
   "metadata": {},
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d566390-d323-40dd-9455-20835299e2f0",
   "metadata": {},
   "source": [
    "### Web scraping is the process of extracting data from websites using automated software tools. Web scraping software (often called \"web crawlers\" or \"spiders\") can automatically visit websites, extract data from web pages, and store the data in a structured format such as a spreadsheet or database.\n",
    "### 1. Data collection: Web scraping can be used to collect data from websites that do not provide an API or other means of accessing their data.\n",
    "### 2. Price comparison: Web scraping can be used to compare prices of products or services from different websites.\n",
    "### 3. Sentiment analysis: Web scraping can be used to gather data from social media platforms or review websites to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0ef9b-c37d-4bdb-aaa6-de0841844acf",
   "metadata": {},
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24291758-e5c0-4bcb-ba0e-c053f8aa1879",
   "metadata": {},
   "source": [
    "### 1. Parsing HTML with Regular Expressions: This method involves using regular expressions to search for patterns in HTML code and extract the desired data. \n",
    "### 2. Using Python Libraries: Python libraries like Beautiful Soup and Scrapy provide tools for parsing HTML and XML files, navigating the parse tree, and extracting data.\n",
    "### 3. APIs: Some websites provide APIs (Application Programming Interfaces) that allow developers to access data in a structured format. \n",
    "### 4. Headless Browsers: This method involves using a headless browser (such as Puppeteer or Selenium) to simulate a user interacting with a website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b841e3d6-a4f9-49bc-8b3c-123a55663de2",
   "metadata": {},
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c75655c-c995-43dc-9c6f-acb3f01ea625",
   "metadata": {},
   "source": [
    "### Beautiful Soup is a Python library used for web scraping purposes to extract data from HTML and XML files. It provides a simple and efficient way to parse the HTML and XML files, extract the relevant data, and manipulate the parsed data.\n",
    "### It allows developers to quickly and easily extract information from HTML and XML files without having to write complex parsing code. With its powerful search capabilities and support for different parsers, Beautiful Soup makes web scraping tasks easier and more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278effeb-fb27-48c3-a909-e1a089c5f796",
   "metadata": {},
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736228a0-3559-442c-9e9a-d04377f9dd87",
   "metadata": {},
   "source": [
    "###  Flask is a lightweight web framework for Python that is often used for building web applications and APIs. Flask is a popular choice for web scraping projects\n",
    "### Web Interface: Flask can be used to create a web interface for the scraped data, making it easy for users to interact with the data and visualize it in different ways.\n",
    "###API: Flask can be used to create a RESTful API for the scraped data, allowing other applications to access the data programmatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfbabd8-7a94-46d5-947e-9dc7df897d65",
   "metadata": {},
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a7204d-2733-46ba-8a4e-e7cde6521d49",
   "metadata": {},
   "source": [
    "###  Elastic Beanstalk is a service for deploying and scaling web applications and services. Upload your code and Elastic Beanstalk automatically handles the deploymentâ€”from capacity provisioning, load balancing, and auto scaling to application health monitoring.\n",
    "### AWS CodePipeline is a fully managed continuous delivery service that helps you automate your release pipelines for fast and reliable application and infrastructure updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107aa642-0450-4f54-bfe4-db284529c153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
